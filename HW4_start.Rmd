---
title: "HW4_start"
author: "Jessica Guo"
date: "11/9/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Libraries
```{r}
library(class)
library(caret)
library(gmodels)
```


## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
library(gmodels)
library(caret)
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))

# Randomize the rows in the data (shuffling the rows)
set.seed(0)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
str(tele_norm)
```

## Getting Train and Test Samples
```{r}
# Selects 10000 random rows for test data
test_set <- sample(1:nrow(tele_norm), 20594) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors 
train <- tele_norm[-test_set,]
test <- tele_norm[test_set,]

train_labels <- tele_norm[-test_set, "yyes"]
test_labels <- tele_norm[test_set, "yyes"]
```


## Regression
```{r}
logmodel = glm(yyes ~ age + jobblue.collar + jobentrepreneur + jobmanagement + jobretired + jobservices + jobstudent + jobtechnician + maritalsingle + educationuniversity.degree + educationunknown + defaultunknown + contacttelephone + monthaug + monthdec + monthjul + monthmar + monthmay + monthnov + monthoct + monthsep + day_of_weekmon + day_of_weekwed + poutcomesuccess + campaign, data = tele_norm, family = binomial)

summary(logmodel)

log_tele <- predict(logmodel, tele_norm, type= "response")
log_tele_yyes <- ifelse(log_tele < 0.5,0,1)
CrossTable(x=tele_norm$yyes, y=log_tele_yyes, prop.chisq=FALSE)
confusionMatrix(as.factor(log_tele_yyes), as.factor(tele_norm$yyes), positive = "1")
```

## KNN Model Predictions
```{r}
#Lets run the KNN command
library(class)
library(caret)
library(gmodels)
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors
#KNN_train <- tele_norm[-test_set, ]
#KNN_train_labels <- tele_norm[-test_set, "yyes"]

##Test
KNN_pred <- test[, match("yyes", names(tele_norm))]
KNN_test_pred <- knn(train = train, test = test, cl = train_labels, k = 3)
CrossTable(x = KNN_pred, y =KNN_test_pred, 
           prop.chisq=FALSE)
confusionMatrix(as.factor(KNN_test_pred),as.factor(test_labels), positive = "1")
```

#ANN Model
```{r}
## Training a model on the data ----
# train the neuralnet model
library(neuralnet)
tele_model <- neuralnet(yyes ~ .,
                            data = train, hidden = 3)

# evaluate the results as we did before
model_results <- compute(tele_model, test)

ANN_prediction <- predict(tele_model, test)
tele_pred <- ifelse(ANN_prediction < 0.5, 0, 1)

CrossTable(x = test$yyes, y = tele_pred, prop.chisq=FALSE)
confusionMatrix(as.factor(tele_pred), as.factor(test$yyes), positive = "1")


```

## SVM Model
```{r}
library(kernlab)

tele2 = tele[sample(1:nrow(tele)), ]

tele_train2 <- tele2[1:20594, ]
tele_test2  <- tele2[20595:41188, ]

tele_classifier <- ksvm(as.factor(y) ~ ., data = tele_train2,
                          kernel = "vanilladot")

tele_classifier
```

```{r}
# predictions on testing dataset
tele2_predictions <- predict(tele_classifier, tele_test2)
head(tele2_predictions)

table(tele2_predictions, tele_test2$y)

# look at agreement vs non-agreement
agreement <- tele2_predictions == tele_test2$y
table(agreement)
prop.table(table(agreement))

```


# Decision Tree
```{r}
install.packages("C50")
```

```{r}
library(C50)

prop.table(table(tele_train2$y))
prop.table(table(tele_test2$y))

tele_dtmodel <- C5.0(y ~ ., data = tele_train2)
dt_predict <- predict(tele_dtmodel, tele_test2)
plot(tele_dtmodel, subtree = 3)

```

```{r}

# cross tabulation of predicted versus actual classes
library(gmodels)
CrossTable(tele_test2$y, dt_predict,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual pick up', 'predicted pick up'))
confusionMatrix(as.factor(dt_predict), as.factor(tele_test2$y), positive = "1")

```

```{r}
combined_prediction <- data.frame(log_tele, KNN_pred, ANN_prediction, tele2_predictions, dt_predict, test$yyes)
summary(combined_prediction)

str(combined_prediction)
```

```{r}

```

