---
title: "HW4_start"
author: "Satvik Suneja, Parth Pandit, Isabella Lian, Sreya Manchiraju, Jessica Guo"
date: "11/9/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Libraries
```{r}
library(class)
library(caret)
library(gmodels)
```


## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
library(gmodels)
library(caret)
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))

# Randomize the rows in the data (shuffling the rows)
set.seed(0)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
str(tele_norm)
```

## Getting Train and Test Samples
```{r}
# Selects 10000 random rows for test data
test_set <- sample(1:nrow(tele_norm), 20594) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors 
train <- tele_norm[-test_set,]
test <- tele_norm[test_set,]

train_labels <- tele_norm[-test_set, "yyes"]
test_labels <- tele_norm[test_set, "yyes"]
```


## Regression
```{r}
logmodel = glm(yyes ~ age + jobblue.collar + jobentrepreneur + jobmanagement + jobretired + jobservices + jobstudent + jobtechnician + maritalsingle + educationuniversity.degree + educationunknown + defaultunknown + contacttelephone + monthaug + monthdec + monthjul + monthmar + monthmay + monthnov + monthoct + monthsep + day_of_weekmon + day_of_weekwed + poutcomesuccess + campaign, data = tele_norm, family = binomial)

summary(logmodel)

log_tele <- predict(logmodel, tele_norm, type= "response")
log_tele_yyes <- ifelse(log_tele < 0.5,0,1)
CrossTable(x=tele_norm$yyes, y=log_tele_yyes, prop.chisq=FALSE)
confusionMatrix(as.factor(log_tele_yyes), as.factor(tele_norm$yyes), positive = "1")
```

```{r}
KNN_train <- tele_norm[-test_set,]
KNN_test <- tele_norm[test_set,]

KNN_train_labels <- tele_norm[-test_set, "yyes"]
KNN_test_labels <- tele_norm[test_set, "yyes"]

KNN_test$yyes = NULL
KNN_train$yyes = NULL

##Test
KNN_pred <- KNN_test[, match("yyes", names(tele_norm))]
KNN_test_pred <- knn(train = KNN_train, test = KNN_test, cl = train_labels, k = 3)
CrossTable(x = KNN_pred, y =KNN_test_pred,
           prop.chisq=FALSE)
confusionMatrix(as.factor(KNN_test_pred),as.factor(test_labels), positive = "1")
```



#ANN Model
```{r}
## Training a model on the data ----
# train the neuralnet model
library(neuralnet)
tele_model <- neuralnet(yyes ~ .,
                            data = train, hidden = 3)

# evaluate the results as we did before
model_results <- compute(tele_model, test)

ANN_prediction <- predict(tele_model, test)
tele_pred <- ifelse(ANN_prediction < 0.5, 0, 1)

CrossTable(x = test$yyes, y = tele_pred, prop.chisq=FALSE)
confusionMatrix(as.factor(tele_pred), as.factor(test$yyes), positive = "1")


```

## SVM Model
```{r}
library(kernlab)

tele2 = tele[sample(1:nrow(tele)), ]

#tele_train2 <- tele2[1:20594, ]
#tele_test2  <- tele2[20595:41188, ]

tele_classifier <- ksvm(as.factor(yyes) ~ ., data = train,
                          kernel = "vanilladot")

tele_classifier
```

```{r}
# predictions on testing dataset
tele2_predictions <- predict(tele_classifier, test)
head(tele2_predictions)

table(tele2_predictions, test$yyes)

# look at agreement vs non-agreement
agreement <- tele2_predictions == test$yyes
table(agreement)
prop.table(table(agreement))

```


# Decision Tree
```{r}
install.packages("C50")
```

```{r}
library(C50)

prop.table(table(train$y))
prop.table(table(test$y))

tele_dtmodel <- C5.0(as.factor(yyes) ~ ., data = train)
dt_predict <- predict(tele_dtmodel, test)
plot(tele_dtmodel, subtree = 4)

```

```{r}

# cross tabulation of predicted versus actual classes
library(gmodels)
CrossTable(test$yyes, dt_predict,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual pick up', 'predicted pick up'))
confusionMatrix(as.factor(dt_predict), as.factor(test$y), positive = "1")

```

```{r}
combined_prediction <- data.frame(log_tele_yyes, KNN_test_pred, tele_pred, tele2_predictions, dt_predict, test$yyes)
summary(combined_prediction)

str(combined_prediction)
```

```{r}
library(kernlab)

teleCombined = combined_prediction[sample(1:nrow(combined_prediction)), ]

tele_trainComb2 <- teleCombined[1:14416, ]
tele_testComb2  <- teleCombined[14416:20594, ]

str(tele_trainComb2)
```

```{r}
library(C50)

prop.table(table(tele_trainComb2$test.yyes))
prop.table(table(tele_testComb2$test.yyes))

tele_dtmodel <- C5.0(as.factor(test.yyes) ~ ., data = tele_trainComb2)
dt_predict <- predict(tele_dtmodel, tele_testComb2)
plot(tele_dtmodel, subtree = 1)

```

```{r}
## Making some mistakes more costly than others
# create a cost matrix
error_cost <- matrix (c(0, 1, 4, 0), nrow=2)
error_cost

# apply the cost matrix to the tree
tele_cost <- C5.0(tele_trainComb2[-6], as.factor(tele_trainComb2$test.yyes), costs = error_cost)
tele_cost_pred <- predict(tele_cost, tele_testComb2)
CrossTable(tele_testComb2$test.yyes, tele_cost_pred, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c("actual success","predicted success"))
confusionMatrix(as.factor(tele_cost_pred), as.factor(tele_testComb2$test.yyes))
```

